{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for fc1.W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc1.B\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2.W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2.B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for fc1.W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc1.B\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2.W\n",
      "Gradient check passed!\n",
      "Checking gradient for fc2.B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666663"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302973, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295379, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.310032, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244372, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265658, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272804, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224503, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260036, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275862, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270213, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268083, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240241, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242428, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.197459, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224302, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262818, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.173246, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.159029, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239333, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214187, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD())\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down and train and val accuracy go up for every epoch\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xb2eb9a828>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.320288, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308694, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285440, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280957, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.305962, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296445, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262654, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.319186, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271776, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239995, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302245, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272388, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257204, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275245, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260624, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291113, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287697, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231597, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.319206, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314088, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296506, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298361, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303190, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296969, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.321930, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311065, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253213, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304075, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277227, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261672, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304935, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255154, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295640, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233971, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.336813, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.324887, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301053, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301550, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.343142, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.320422, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.310565, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.315559, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.312014, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.253984, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.266984, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.298676, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.302245, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.151539, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.238692, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.746749, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.011311, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.353158, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.024687, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.099982, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.167278, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.738001, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.091394, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.416787, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.349164, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.171151, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.190226, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.544806, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.423781, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.781875, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.913972, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.712991, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 2.152727, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.456778, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.119971, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.727869, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.501355, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.983862, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 2.214750, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.277069, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.867016, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.555313, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.716826, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.761239, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.629777, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.820519, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.859652, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 2.018306, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.750363, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.527552, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.600455, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.636371, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.447574, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.901748, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.603705, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.347067, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.564005, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.252047, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.114017, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.978901, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.968684, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.737057, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.547167, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.259637, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.014640, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.312443, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.417459, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.940796, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.678975, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.744472, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.793200, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.040619, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.318571, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.088133, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.131251, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.242457, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.972788, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.656886, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.572942, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.249714, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 2.012796, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.656481, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.282338, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.223303, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.304897, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.694443, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.665723, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602859, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.968264, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.446594, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.031793, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.681061, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.301522, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.320337, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.024284, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.501504, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.647311, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.134486, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.252151, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.884261, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.399165, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.150924, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.293731, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.415678, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.458337, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.587924, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.178072, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.673346, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.713300, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.501999, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.948576, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.424462, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.110623, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.282686, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.361684, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.506257, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.391703, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.522281, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.135116, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.411837, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.351925, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.196320, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.498357, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.292531, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.636656, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.552343, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.700920, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.086009, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.154692, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.439583, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.168427, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.488932, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.078446, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.561994, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.107840, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.328204, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.449517, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.256413, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.493614, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.373828, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.136998, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.421355, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.450209, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.621627, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.429008, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.465302, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.355663, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.334306, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.365827, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.346051, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.487345, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.217036, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.351660, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.146264, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302488, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.281242, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.287676, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.274920, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.275679, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.143017, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.946931, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.686031, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.923267, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.779455, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.196416, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.484722, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.470823, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.706112, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.491943, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.592331, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.491001, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 0.976746, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 0.961513, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.369020, Train accuracy: 0.800000, val accuracy: 0.066667\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 1000, reg = 1e-6)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **40%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 2.299858, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.260287, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.229302, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.306115, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.247134, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.308816, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.096561, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.228029, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.038183, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.351519, Train accuracy: 0.198889, val accuracy: 0.210000\n",
      "Epoch 100: Loss: 2.093281, Train accuracy: 0.224000, val accuracy: 0.229000\n",
      "Epoch 110: Loss: 1.964371, Train accuracy: 0.247778, val accuracy: 0.246000\n",
      "Epoch 120: Loss: 2.078221, Train accuracy: 0.264556, val accuracy: 0.262000\n",
      "Epoch 130: Loss: 2.095616, Train accuracy: 0.280111, val accuracy: 0.285000\n",
      "Epoch 140: Loss: 2.203877, Train accuracy: 0.302000, val accuracy: 0.308000\n",
      "Epoch 150: Loss: 2.062030, Train accuracy: 0.336889, val accuracy: 0.336000\n",
      "Epoch 160: Loss: 1.826322, Train accuracy: 0.367333, val accuracy: 0.376000\n",
      "Epoch 170: Loss: 1.452563, Train accuracy: 0.395444, val accuracy: 0.389000\n",
      "Epoch 180: Loss: 1.822235, Train accuracy: 0.422667, val accuracy: 0.411000\n",
      "Epoch 190: Loss: 1.400421, Train accuracy: 0.444556, val accuracy: 0.430000\n",
      "New contender with 0.0001/1e-06/128/0.999\n",
      "Epoch 0: Loss: 2.296278, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.215810, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.202904, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.275939, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.147861, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.190171, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.253250, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.223006, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.163146, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.133740, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.119672, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 110: Loss: 2.270854, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 120: Loss: 2.361873, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 130: Loss: 2.240181, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 140: Loss: 2.220802, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 150: Loss: 2.298648, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 160: Loss: 2.014523, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 170: Loss: 2.222729, Train accuracy: 0.197444, val accuracy: 0.208000\n",
      "Epoch 180: Loss: 2.120681, Train accuracy: 0.200889, val accuracy: 0.210000\n",
      "Epoch 190: Loss: 1.907416, Train accuracy: 0.204000, val accuracy: 0.212000\n",
      "Epoch 0: Loss: 2.298888, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.283377, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.297952, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.201500, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.260608, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.233125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.262807, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.344328, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.228348, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.352526, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.176345, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 110: Loss: 2.264013, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 120: Loss: 2.219099, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 130: Loss: 2.211066, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 140: Loss: 2.160834, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 150: Loss: 2.171032, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 160: Loss: 2.151741, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 170: Loss: 2.290896, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 180: Loss: 2.286476, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 190: Loss: 2.124124, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 0: Loss: 2.289966, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.271078, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.158192, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.293144, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.337744, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.272441, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.404768, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.350567, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.111152, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.336758, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 1.844514, Train accuracy: 0.217889, val accuracy: 0.225000\n",
      "Epoch 110: Loss: 2.201059, Train accuracy: 0.248889, val accuracy: 0.254000\n",
      "Epoch 120: Loss: 2.090236, Train accuracy: 0.268111, val accuracy: 0.267000\n",
      "Epoch 130: Loss: 2.240704, Train accuracy: 0.277111, val accuracy: 0.277000\n",
      "Epoch 140: Loss: 2.272485, Train accuracy: 0.282000, val accuracy: 0.279000\n",
      "Epoch 150: Loss: 1.972313, Train accuracy: 0.291889, val accuracy: 0.299000\n",
      "Epoch 160: Loss: 1.775128, Train accuracy: 0.327556, val accuracy: 0.329000\n",
      "Epoch 170: Loss: 2.124289, Train accuracy: 0.364333, val accuracy: 0.359000\n",
      "Epoch 180: Loss: 1.778741, Train accuracy: 0.390333, val accuracy: 0.387000\n",
      "Epoch 190: Loss: 1.657170, Train accuracy: 0.413444, val accuracy: 0.405000\n",
      "Epoch 0: Loss: 2.289114, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.238015, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.201914, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.116620, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.182740, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.270720, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.123650, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.274859, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.319178, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.133702, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.301238, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 110: Loss: 2.299063, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 120: Loss: 1.910287, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 130: Loss: 2.218283, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 140: Loss: 2.264191, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 150: Loss: 2.116139, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 160: Loss: 2.097752, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 170: Loss: 2.269354, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 180: Loss: 1.990977, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 190: Loss: 2.253791, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 0: Loss: 2.294009, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.298277, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.301105, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.318469, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.381855, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.194054, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.257184, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.250134, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.273698, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Loss: 2.230372, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.260444, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 110: Loss: 2.283982, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 120: Loss: 2.323186, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 130: Loss: 2.254893, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 140: Loss: 2.195602, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 150: Loss: 2.209442, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 160: Loss: 2.194901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 170: Loss: 2.314996, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 180: Loss: 2.349593, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 190: Loss: 2.267152, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 0: Loss: 2.289180, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.274592, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.084994, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.214873, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.077541, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.132285, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.297464, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 1.933551, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.305725, Train accuracy: 0.196889, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.269779, Train accuracy: 0.221889, val accuracy: 0.227000\n",
      "Epoch 100: Loss: 2.116489, Train accuracy: 0.252222, val accuracy: 0.255000\n",
      "Epoch 110: Loss: 1.993444, Train accuracy: 0.272000, val accuracy: 0.270000\n",
      "Epoch 120: Loss: 2.147292, Train accuracy: 0.282111, val accuracy: 0.283000\n",
      "Epoch 130: Loss: 1.815390, Train accuracy: 0.299556, val accuracy: 0.308000\n",
      "Epoch 140: Loss: 1.962295, Train accuracy: 0.336444, val accuracy: 0.340000\n",
      "Epoch 150: Loss: 1.689740, Train accuracy: 0.372889, val accuracy: 0.369000\n",
      "Epoch 160: Loss: 1.623400, Train accuracy: 0.402111, val accuracy: 0.391000\n",
      "Epoch 170: Loss: 1.558067, Train accuracy: 0.426667, val accuracy: 0.414000\n",
      "Epoch 180: Loss: 1.670511, Train accuracy: 0.450444, val accuracy: 0.432000\n",
      "Epoch 190: Loss: 1.163964, Train accuracy: 0.469111, val accuracy: 0.466000\n",
      "New contender with 0.0001/1e-06/256/0.999\n",
      "Epoch 0: Loss: 2.290724, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.223824, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.204714, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.332469, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.311337, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.088896, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.196680, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.156746, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.278587, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.315225, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.149902, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 110: Loss: 2.274324, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 120: Loss: 2.293098, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 130: Loss: 2.165640, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 140: Loss: 2.179485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 150: Loss: 2.018972, Train accuracy: 0.197111, val accuracy: 0.208000\n",
      "Epoch 160: Loss: 2.168791, Train accuracy: 0.200778, val accuracy: 0.213000\n",
      "Epoch 170: Loss: 2.262211, Train accuracy: 0.205333, val accuracy: 0.213000\n",
      "Epoch 180: Loss: 2.198893, Train accuracy: 0.210667, val accuracy: 0.214000\n",
      "Epoch 190: Loss: 2.183402, Train accuracy: 0.215444, val accuracy: 0.220000\n",
      "Epoch 0: Loss: 2.292577, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.292263, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.280443, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.174294, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.287449, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.284472, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.304579, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.331109, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.232157, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.215934, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.362999, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 110: Loss: 2.276777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 120: Loss: 2.344013, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 130: Loss: 2.351770, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 140: Loss: 2.227276, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 150: Loss: 2.225526, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 160: Loss: 2.181891, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 170: Loss: 2.220714, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 180: Loss: 2.273629, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 190: Loss: 2.292025, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 0: Loss: 2.291475, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.242632, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.260855, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.329448, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.134875, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.110021, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.319450, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.185682, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.401047, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 1.873799, Train accuracy: 0.204333, val accuracy: 0.211000\n",
      "Epoch 100: Loss: 2.143082, Train accuracy: 0.232778, val accuracy: 0.234000\n",
      "Epoch 110: Loss: 2.083985, Train accuracy: 0.254000, val accuracy: 0.252000\n",
      "Epoch 120: Loss: 1.919969, Train accuracy: 0.270778, val accuracy: 0.271000\n",
      "Epoch 130: Loss: 2.092779, Train accuracy: 0.280889, val accuracy: 0.285000\n",
      "Epoch 140: Loss: 2.003565, Train accuracy: 0.301667, val accuracy: 0.308000\n",
      "Epoch 150: Loss: 1.973227, Train accuracy: 0.329889, val accuracy: 0.337000\n",
      "Epoch 160: Loss: 1.522293, Train accuracy: 0.364000, val accuracy: 0.371000\n",
      "Epoch 170: Loss: 1.798735, Train accuracy: 0.397222, val accuracy: 0.388000\n",
      "Epoch 180: Loss: 1.938024, Train accuracy: 0.422444, val accuracy: 0.406000\n",
      "Epoch 190: Loss: 1.709234, Train accuracy: 0.441222, val accuracy: 0.437000\n",
      "Epoch 0: Loss: 2.297816, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.177939, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.317656, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.150161, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.361795, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.238625, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.179930, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.148543, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.233950, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.326967, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.175336, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 110: Loss: 2.182010, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 120: Loss: 2.203909, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 130: Loss: 2.096405, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 140: Loss: 2.161660, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 150: Loss: 2.088592, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 160: Loss: 2.209623, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170: Loss: 2.052832, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 180: Loss: 2.105840, Train accuracy: 0.196778, val accuracy: 0.206000\n",
      "Epoch 190: Loss: 2.367931, Train accuracy: 0.199556, val accuracy: 0.206000\n",
      "Epoch 0: Loss: 2.302501, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.304397, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.270860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.195264, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.162877, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.294999, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.219525, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.173139, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.233074, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.271722, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.359186, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 110: Loss: 2.229036, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 120: Loss: 2.300894, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 130: Loss: 2.229077, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 140: Loss: 2.127577, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 150: Loss: 2.175309, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 160: Loss: 2.300624, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 170: Loss: 2.157003, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 180: Loss: 2.168741, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 190: Loss: 2.269794, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 0: Loss: 2.301816, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.248488, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.204441, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.189243, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.230999, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.316916, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.436252, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.095899, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.358208, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.140791, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.138404, Train accuracy: 0.212889, val accuracy: 0.219000\n",
      "Epoch 110: Loss: 2.099242, Train accuracy: 0.237333, val accuracy: 0.241000\n",
      "Epoch 120: Loss: 1.965192, Train accuracy: 0.257444, val accuracy: 0.257000\n",
      "Epoch 130: Loss: 1.956832, Train accuracy: 0.270000, val accuracy: 0.267000\n",
      "Epoch 140: Loss: 2.059132, Train accuracy: 0.277444, val accuracy: 0.279000\n",
      "Epoch 150: Loss: 2.236708, Train accuracy: 0.287333, val accuracy: 0.290000\n",
      "Epoch 160: Loss: 2.202626, Train accuracy: 0.303000, val accuracy: 0.306000\n",
      "Epoch 170: Loss: 1.942838, Train accuracy: 0.325556, val accuracy: 0.318000\n",
      "Epoch 180: Loss: 1.690613, Train accuracy: 0.357000, val accuracy: 0.352000\n",
      "Epoch 190: Loss: 1.978380, Train accuracy: 0.389444, val accuracy: 0.373000\n",
      "Epoch 0: Loss: 2.293847, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.227367, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.182378, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.195884, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.301749, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.242182, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.330698, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.331315, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.168952, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.250629, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.190607, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 110: Loss: 2.162983, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 120: Loss: 2.090985, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 130: Loss: 2.283579, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 140: Loss: 2.228999, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 150: Loss: 2.313580, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 160: Loss: 2.145076, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 170: Loss: 2.278451, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 180: Loss: 1.991851, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 190: Loss: 2.219932, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 0: Loss: 2.295368, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.254044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.308809, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.244750, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.260337, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.225774, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.279211, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.126071, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.110905, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.186513, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.318280, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 110: Loss: 2.181424, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 120: Loss: 2.320816, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 130: Loss: 2.239028, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 140: Loss: 2.262107, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 150: Loss: 2.259700, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 160: Loss: 2.221860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 170: Loss: 2.238125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 180: Loss: 2.151263, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 190: Loss: 2.215727, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 0: Loss: 2.292582, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.246788, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.327014, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.213925, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.202423, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.258837, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 60: Loss: 2.116640, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.130756, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 1.962491, Train accuracy: 0.201111, val accuracy: 0.211000\n",
      "Epoch 90: Loss: 2.333721, Train accuracy: 0.230333, val accuracy: 0.232000\n",
      "Epoch 100: Loss: 2.018754, Train accuracy: 0.257222, val accuracy: 0.257000\n",
      "Epoch 110: Loss: 2.168873, Train accuracy: 0.273778, val accuracy: 0.274000\n",
      "Epoch 120: Loss: 2.009373, Train accuracy: 0.281667, val accuracy: 0.282000\n",
      "Epoch 130: Loss: 1.889148, Train accuracy: 0.296333, val accuracy: 0.298000\n",
      "Epoch 140: Loss: 1.663813, Train accuracy: 0.328222, val accuracy: 0.333000\n",
      "Epoch 150: Loss: 1.532675, Train accuracy: 0.366444, val accuracy: 0.359000\n",
      "Epoch 160: Loss: 1.779736, Train accuracy: 0.393444, val accuracy: 0.379000\n",
      "Epoch 170: Loss: 1.478192, Train accuracy: 0.419778, val accuracy: 0.405000\n",
      "Epoch 180: Loss: 1.418461, Train accuracy: 0.443111, val accuracy: 0.426000\n",
      "Epoch 190: Loss: 1.753007, Train accuracy: 0.464000, val accuracy: 0.452000\n",
      "Epoch 0: Loss: 2.302145, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.339743, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.174548, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.253541, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.072908, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 50: Loss: 2.298476, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Loss: 2.264747, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 70: Loss: 2.273054, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 80: Loss: 2.248016, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 90: Loss: 2.355309, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 100: Loss: 2.103389, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 110: Loss: 2.157998, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 120: Loss: 2.184972, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 130: Loss: 2.313381, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 140: Loss: 2.288496, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 150: Loss: 1.841161, Train accuracy: 0.196889, val accuracy: 0.206000\n",
      "Epoch 160: Loss: 1.997577, Train accuracy: 0.200333, val accuracy: 0.213000\n",
      "Epoch 170: Loss: 2.140042, Train accuracy: 0.206000, val accuracy: 0.213000\n",
      "Epoch 180: Loss: 2.154472, Train accuracy: 0.210667, val accuracy: 0.217000\n",
      "Epoch 190: Loss: 2.124686, Train accuracy: 0.215667, val accuracy: 0.223000\n",
      "Epoch 0: Loss: 2.287324, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 10: Loss: 2.250352, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 20: Loss: 2.210558, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 30: Loss: 2.198811, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 40: Loss: 2.267452, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [1e-4, 1e-5, 1e-3]\n",
    "reg_strength = [1e-6, 1e-7, 1e-4, 1e-5]\n",
    "learning_rate_decay = [0.999, 0.99, 0.95]\n",
    "hidden_layer_size = [128, 64, 256]\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "for lr in learning_rates:\n",
    "    for reg in reg_strength:\n",
    "        for ls in hidden_layer_size:\n",
    "            for decay in learning_rate_decay:\n",
    "                classifier = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = ls, reg = reg)\n",
    "                trainer = Trainer(classifier, dataset, MomentumSGD(), learning_rate=lr, learning_rate_decay=decay, num_epochs=num_epochs)\n",
    "                lh, tr_h, val_h = trainer.fit()\n",
    "                acc = val_h[-1]\n",
    "                if best_val_accuracy is None or acc > best_val_accuracy:\n",
    "                    best_classifier = classifier\n",
    "                    best_val_accuracy = acc\n",
    "                    loss_history = lh\n",
    "                    val_history = val_h\n",
    "                    train_history = tr_h\n",
    "                    print(\"New contender with {lr}/{reg}/{ls}/{decay}\".format(lr=lr, reg=reg, ls=ls, decay=decay))\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
